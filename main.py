import os
import fitz  # PyMuPDF
import faiss
import numpy as np
import gradio as gr
from sentence_transformers import SentenceTransformer
import requests
import webbrowser
import threading
import time

# 1. PDF â†’ í…ìŠ¤íŠ¸
def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    return "\n".join([page.get_text() for page in doc])

# 2. í…ìŠ¤íŠ¸ â†’ ë¬¸ë‹¨ ë‚˜ëˆ„ê¸°
def chunk_text(text, size=500):
    return [text[i:i+size] for i in range(0, len(text), size)]

# 3. ë¬¸ë‹¨ â†’ ì„ë² ë”© + ì¸ë±ì‹±
def build_faiss(chunks, embed_model):
    embeddings = embed_model.encode(chunks)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    return index, embeddings, chunks

# 4. ì§ˆì˜ â†’ ìœ ì‚¬ ë¬¸ë‹¨ ê²€ìƒ‰
def search_similar(query, embed_model, index, chunks, k=3):
    q_emb = embed_model.encode([query])
    D, I = index.search(np.array(q_emb), k)
    return [chunks[i] for i in I[0]]

# 5. ë¡œì»¬ LLMì— í”„ë¡¬í”„íŠ¸ ìš”ì²­
def query_local_llm(prompt, model_name, api_url="http://127.0.0.1:1234/v1/chat/completions"):
    headers = {"Content-Type": "application/json"}
    payload = {
        "model": model_name,
        "messages": [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ì„¤ëª…í•´ì£¼ëŠ” ì¡°ìˆ˜ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7
    }
    try:
        res = requests.post(api_url, json=payload, headers=headers)
        return res.json()["choices"][0]["message"]["content"]
    except Exception as e:
        return f"Error: {str(e)}"

# PDF íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_pdf_files():
    directory = "./docs"
    if not os.path.exists(directory):
        os.makedirs(directory)
    return [f for f in os.listdir(directory) if f.lower().endswith('.pdf')]

# ê·¸ë¼ë””ì˜¤ ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜
def analyze_pdf(pdf_filename, user_question, model_name, api_url):
    if not pdf_filename:
        return "PDF íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
    
    if not user_question:
        return "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    if not model_name:
        return "LLM ëª¨ë¸ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    if not api_url:
        api_url = "http://127.0.0.1:1234/v1/chat/completions"
    
    try:
        # ì „ì²´ ê²½ë¡œ êµ¬ì„±
        pdf_path = os.path.join("./docs", pdf_filename)
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        embed_model = SentenceTransformer("all-MiniLM-L6-v2")
        
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        progress_text = f"ğŸ“„ '{pdf_filename}' íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘...\n"
        raw_text = extract_text_from_pdf(pdf_path)
        
        # ë¬¸ë‹¨ ë‚˜ëˆ„ê¸°
        chunks = chunk_text(raw_text)
        
        # ì„ë² ë”© ë° ì¸ë±ì‹±
        progress_text += "ğŸ“ ì„ë² ë”© ë° ì¸ë±ì‹± ì¤‘...\n"
        index, _, chunks = build_faiss(chunks, embed_model)
        
        # ìœ ì‚¬ ë¬¸ë‹¨ ê²€ìƒ‰
        progress_text += "ğŸ” ì§ˆë¬¸ì— ê´€ë ¨ëœ ë¬¸ë‹¨ ê²€ìƒ‰ ì¤‘...\n"
        related = search_similar(user_question, embed_model, index, chunks)
        
        # ë¡œì»¬ AIì— ì§ˆì˜
        progress_text += f"ğŸ§  ë¡œì»¬ AI ({model_name})ì—ê²Œ ì§ˆì˜ ì¤‘...\n\n"
        context = "\n\n".join(related)
        prompt = f"ë‹¤ìŒ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:\n\n{context}\n\nì§ˆë¬¸: {user_question}"
        answer = query_local_llm(prompt, model_name, api_url)
        
        # ê²°ê³¼ ë°˜í™˜
        result = f"{progress_text}-------- ë¶„ì„ ê²°ê³¼ --------\n\n{answer}"
        return result
    
    except Exception as e:
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ë¸Œë¼ìš°ì € ìë™ ì‹¤í–‰ í•¨ìˆ˜
def open_browser(port=7860):
    def _open_browser():
        # ì„œë²„ê°€ ì‹œì‘ë  ì‹œê°„ì„ ì£¼ê¸° ìœ„í•´ 2ì´ˆ ëŒ€ê¸°
        time.sleep(2)
        # ê¸°ë³¸ ë¸Œë¼ìš°ì €ë¡œ Gradio í˜ì´ì§€ ì—´ê¸°
        webbrowser.open(f'http://127.0.0.1:{port}')
    
    # ë³„ë„ì˜ ìŠ¤ë ˆë“œì—ì„œ ë¸Œë¼ìš°ì € ì—´ê¸°
    threading.Thread(target=_open_browser).start()

# Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
with gr.Blocks(title="PDF ë¶„ì„ê¸°") as app:
    gr.Markdown("# ğŸ“„ PDF ë¶„ì„ê¸°")
    gr.Markdown("docs í´ë”ì— ìˆëŠ” PDF íŒŒì¼ì„ ì„ íƒí•˜ê³  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    
    with gr.Row():
        with gr.Column(scale=1):
            # PDF íŒŒì¼ ì„ íƒ ë“œë¡­ë‹¤ìš´
            pdf_dropdown = gr.Dropdown(
                label="PDF íŒŒì¼ ì„ íƒ", 
                choices=get_pdf_files(),
                interactive=True
            )
            
            # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
            refresh_btn = gr.Button("ğŸ“‚ íŒŒì¼ ëª©ë¡ ìƒˆë¡œê³ ì¹¨")
            
            # ì§ˆë¬¸ ì…ë ¥
            question_input = gr.Textbox(
                label="ì§ˆë¬¸ ì…ë ¥",
                placeholder="ì˜ˆ: ì´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜",
                lines=3
            )
            
            # LLM ëª¨ë¸ ì´ë¦„ ì…ë ¥ (í…ìŠ¤íŠ¸ í•„ë“œ)
            model_input = gr.Textbox(
                label="LM Studio ëª¨ë¸ ì´ë¦„ ì…ë ¥",
                placeholder="ëª¨ë¸ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: llama-dna-1.0-8b-instruct)",
                value="llama-dna-1.0-8b-instruct"
            )
            
            # API URL ì…ë ¥
            api_url_input = gr.Textbox(
                label="API URL (ì„ íƒì‚¬í•­)",
                placeholder="http://127.0.0.1:1234/v1/chat/completions",
                value="http://127.0.0.1:1234/v1/chat/completions"
            )
            
            # ë¶„ì„ ë²„íŠ¼
            analyze_btn = gr.Button("ğŸ” ë¶„ì„í•˜ê¸°", variant="primary")
        
        with gr.Column(scale=2):
            # ê²°ê³¼ ì¶œë ¥
            result_output = gr.Textbox(
                label="ë¶„ì„ ê²°ê³¼",
                lines=15,
                placeholder="ë¶„ì„ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤..."
            )
    
    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ ì´ë²¤íŠ¸
    def refresh_pdf_list():
        return gr.Dropdown(choices=get_pdf_files())
    
    refresh_btn.click(refresh_pdf_list, outputs=[pdf_dropdown])
    
    # ë¶„ì„ ë²„íŠ¼ ì´ë²¤íŠ¸
    analyze_btn.click(
        analyze_pdf, 
        inputs=[pdf_dropdown, question_input, model_input, api_url_input], 
        outputs=[result_output]
    )
    
    # ë„ì›€ë§ í‘œì‹œ
    gr.Markdown("""
    ## ì‚¬ìš© ë°©ë²•
    1. docs í´ë”ì— ë¶„ì„í•  PDF íŒŒì¼ì„ ë„£ìœ¼ì„¸ìš”.
    2. PDF íŒŒì¼ì„ ì„ íƒí•˜ê³  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.
    3. LM Studioì—ì„œ ë¡œë“œí•œ ëª¨ë¸ì˜ ì´ë¦„ì„ ì •í™•íˆ ì…ë ¥í•˜ì„¸ìš”.
    4. API URLì´ ê¸°ë³¸ê°’ê³¼ ë‹¤ë¥¸ ê²½ìš° ìˆ˜ì •í•˜ì„¸ìš”.
    5. 'ë¶„ì„í•˜ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.
    
    ## ì£¼ì˜ì‚¬í•­
    - LM Studioì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ ì´ë¦„ì„ ì •í™•íˆ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.
    - LM Studio API ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    """)

# ê·¸ë¼ë””ì˜¤ ì•± ì‹¤í–‰
if __name__ == "__main__":
    # ë¸Œë¼ìš°ì € ìë™ ì‹¤í–‰ í•¨ìˆ˜ í˜¸ì¶œ
    open_browser()
    
    # Gradio ì•± ì‹¤í–‰
    app.launch(share=False)